[["index.html", "Start with PoissonERM: Automate the Binary-Endpoint ER model via Poisson Regression Chapter 1 Introduction", " Start with PoissonERM: Automate the Binary-Endpoint ER model via Poisson Regression Yuchen Wang, Ph.D., Pfizer Inc Luke Fostvedt, Ph.D., Pfizer Inc 2023-11-10 Chapter 1 Introduction PoissonERM is a tool that was developed as an automation tool for Poisson Regression of binary events (eg occurrence of AEs) for internal use at Pfizer Inc. It implements a full statistical analysis using Poisson Regression on endpoint(s) specified by the user. There is also the ability to predict the incidence rate using user provided simulated exposures (usually from a separate population PK model). PoissonERM is the package version of this tool, which can generate an R Markdown report summary that includes all the components typically included in a formal report. Poisson regression of binary outcome data utilizes the features of the exponential family of distributions. For the purposes of the analysis that is performed with this package, there are two aspect to highlight. the link function for Poisson regression is log() instead of logit; Poisson regression can incorporate time to model the incidence rate. This tutorial is a document of the methods implemented in PoissonERM and the instruction for users. Section 2 Quick Start With the Example is for users to start with provided example folders (https://github.com/yuchenw2015/PoissonERM-Example). It shows how to run functions in PoissonERM when the control scripts and data sets are ready. Section 7 provides ideas for users to explore the different options in the example control script. Section 3 Usage introduces the basic uses of 3 functions in PoissonERM. Section 4 Data Preparation shows the data structure of the modeling data set and of the new simulated exposure data set. Section 5 and Section 6 are detailed explanations of the two control scripts. Ideally, user should prepare the data sets and the control scripts before running functions in PoissonERM. To install the package, go to https://github.com/yuchenw2015/PoissonERM. The full section of the analysis method can be found here: https://yuchenw2015.github.io/PoissonERM. The examples mentioned in this tutorial are here: https://github.com/yuchenw2015/PoissonERM-Example. "],["quick-start-with-an-example.html", "Chapter 2 Quick Start with an Example", " Chapter 2 Quick Start with an Example This section demonstrates the usage of PoissonERM using simulated data set. The example folders are here: https://github.com/yuchenw2015/PoissonERM-Example. Each example folder contains: user-input.r: control script for modeling where setting and details about the analysis, exposures, covariates, and output are declared obsdata.csv: data set for modeling prediction-user-input-sim.r: control script for prediction of new simulated exposures. (optional) simdata.csv: new simulated exposures. (required when using the prediction-user-input-sim.r functionality) There are 3 main functions in PoissonERM: ModelPoisson(): establish E-R relationship between exposures and endpoints via Poisson Regression. PredictionPoisson(): generate prediction figure and table using the base model and the new simulated exposures. ReportPoisson(): generate a report of the modeling results, with/without the prediction results. The folders Example1 (with prediction) and Example2 (no prediction) contain all necessary files (control scripts or data sets) to run functions in PoissonERM. Details of the example inputs and datasets used: 2 Exposure Metrics, 3 Categorical Covariates and 2 Continuous Covariates were considered in all 3 Endpoints; All exposures, covariates and events were summarized by protocol number (PROT). Threshold of low incidence rate was 10% therefore only 2 endpoints were considered in this analysis (Adverse Event 1 was with incidence rate lower than 10%). Event sub-type was provided for all endpoints, which breaks down the observed with event and not observed with event outcomes into more detailed classification. Included covariates in final model if there is any proper one(s). Considered log- and sqrt-transformation for exposure metrics. Considered log-transformation for continuous covariates. No reference value for continuous covariates. Exposure selection conducted following \\(p\\)-value significance criteria, and backwards deletion did not remove exposure metric regardless of significance. Final model may not contain exposure metric if none meet the exposure selection criteria. Tables are all saved as .tex (LaTex format). Example-completed is a completed analysis folder using the same control scripts and data sets as folder Example1. library(PoissonERM) rm(list = ls(all = TRUE)) folder.dir1 &lt;- &quot;PoissonERM/Example1/&quot; #change the path accordingly ModelPoisson(pathRunType = folder.dir1, user.input = &quot;user-input.r&quot;) PredictionPoisson(pathRunType = getwd(), prediction.input = &quot;prediction-user-input-sim.R&quot;, model.RData = &quot;myEnvironment.RData&quot;) ReportPoisson(pathRunType = getwd(), model.RData = &quot;myEnvironment.RData&quot;, file.name = &quot;Report_with_pred.Rmd&quot;) rm(list = ls(all = TRUE)) folder.dir2 &lt;- &quot;PoissonERM/Example2/&quot; #change the path accordingly ModelPoisson(pathRunType = folder.dir2, user.input = &quot;user-input.r&quot;) ReportPoisson(pathRunType = getwd(), model.RData = &quot;myEnvironment.RData&quot;, file.name = &quot;Report_no_pred.Rmd&quot;) Running this script will perform the complete statistical analysis and generate an .Rmd report (which is ready to knit) with all the details, results, simulations, and conclusions for each example. "],["usage.html", "Chapter 3 Usage 3.1 Statistical Analysis: ModelPoisson() 3.2 New Predictions PredictionPoisson() 3.3 Report Generation: ReportPoisson()", " Chapter 3 Usage The complete statistical modeling, including data checks, data imputation, covariate screening, model selection, simulations and model summaries are all wrapped into the ModelPoisson() function. Only a control script and dataset are required. All of the output from the modeling is saved into summary folders and endpoint specific folders. 3.1 Statistical Analysis: ModelPoisson() rm(list = ls(all = TRUE)) folder.dir &lt;- getwd() ModelPoisson(pathRunType = folder.dir, user.input = &quot;user-input.r&quot;, clean = TRUE, save.name = &quot;myEnvironment.RData) pathRunType: The directory where the control scripts and data sets are. All the modeling results will be saved to this directory as well. Must be an absolute path. Default value is getwd(). user.input: The file path of the control script (user-input.r) to source. Default value is NULL. If user.input is NULL, user needs to run/source the control file first then run ModelPoisson() as rm(list = ls(all = TRUE)) folder.dir &lt;- getwd() source(&quot;user-input.r&quot;) ModelPoisson(pathRunType = folder.dir, user.input = NULL, clean = TRUE, save.name = &quot;myEnvironment.RData&quot;) clean: If TRUE, clean the folders under the directory pathRunType before running a new analysis. Default value of clean is TRUE. save.name: The modeling results and users modeling options are saved as .RData with the provided name under the directory pathRunType. Default value is myEnvironment.RData. If the analysis was conducted successfully, several folders will have been created. Demog-Sum folder contains summary tables of events, exposures, and covariates. Cov-EDA folder contains figures of covariates correlation, exposure summary, and event summary vs time. A folder is created for each Endpoint has a folder with the user-specified endpoint name. There will be subfolders within each of the endpoint folders containing: a sub-dataset RData file which was used in modeling this endpoint; Models folder containing the saved modeling R objects, the model summary tables, and backwards deletion log. OR folder containing the saved Odds-Ratio tables and figures if the final model contains any proper covariates. 3.2 New Predictions PredictionPoisson() The modeling results from ModelPoisson() can be used for predicting the incidence rate of new specific groups such as treatment groups, patient populations, Age groups etc to reflect the different incidence rates due to the different exposure levels. PoissonERM provides easy way to use base model (ignoring covariates) in predicting incidence rate for new simulated exposures and to compare it with the observed incidence rates grouped by exposure level. If there is no significant exposure response relationship, the prediction output will only includes the summary of the observed incidence rates and the provided new simulated exposures i.e. no predicted incidence rate results. folder.dir &lt;- getwd() PredictionPoisson(pathRunType = folder.dir, prediction.input = &quot;prediction-user-input-sim.R&quot;, model.RData = &quot;myEnvironment.RData&quot;, save.name = &quot;myEnvironment_new.RData&quot;) PredictionPoisson() creates one folder Prediction under each endpoint folder which contains new exposure summary and incidence rate summary. The figures are saved in multiple sizes and can be used as needed. pathRunType: The directory where the control scripts and data sets are. All the results will be saved to this directory as well. Must be an absolute path. Default value is getwd(). prediction.input: The file path of the control script (prediction-user-input-sim.r) to source. Default value is NULL. If prediction.input is NULL, user needs to run/source the control file first then run PredictionPoisson() as folder.dir &lt;- getwd() source(&quot;prediction-user-input-sim.R&quot;) ModelPoisson(pathRunType = folder.dir, prediction.input = NULL, model.RData = &quot;myEnvironment.RData&quot;, save.name = &quot;myEnvironment_new.RData&quot;) model.RData: The saved modeling result object from ModelPoisson(), must be located under directory pathRunType. Default value is myEnvironment.RData, which is the default save.name value in function ModelPoisson(). save.name: The modeling results and the prediction results are saved as .RData with the provided name under the directory pathRunType. Default value is model.RData, which will rewrite the previously saved modeling result. 3.3 Report Generation: ReportPoisson() The modeling results from ModelPoisson() or PredictionPoisson()can be used to generate an automated .Rmd report. Notice that the report cannot be generated using the modeling results from ModelPoisson() if there is a Prediction folder in each endpoint result folder. If the user wants to generate report without prediction results after running PredictionPoisson(), user may remove those Prediction folders manually or simply clean the R Environment and rerun ModelPoisson() with clean = TRUE. folder.dir &lt;- getwd() ReportPoisson(pathRunType = folder.dir, model.RData = &quot;myEnvironment.RData&quot;, file.name = &quot;Report.Rmd&quot;) pathRunType: The directory where the previously saved modeling results (folders and the saved .RData file) located. The generated .Rmd report will be saved to this directory. Must be an absolute path. Default value is getwd(). model.RData: The saved modeling result object from ModelPoisson() or from PredictionPoisson(), must be located under directory pathRunType. Default value is myEnvironment.RData, which is the default save.name value in function ModelPoisson(). file.name: The file name for the generated report. The default value is NULL. If file.name is NULL or if file.name is not ended with .Rmd, the default file name will be Poisson-Regression-Date&amp;Time.Rmd. The saved .Rmd file can compile .html report via Knit without any further modification. It could be used as an initial draft of a comprehensive report. "],["data-preparation.html", "Chapter 4 Data Preparation 4.1 Data Set for Modeling 4.2 New Exposure Data Set for Prediction", " Chapter 4 Data Preparation 4.1 Data Set for Modeling PoissonERM is designed for implementing standard binary-endpoint E-R analysis on multiple endpoints. The data set must include: A column of C, where any non-NA value indicates dropping the row and NA value indicates including the row in modeling; One column of unique Subject ID where the same ID indicates the same subject; One column of Outcome where 0 indicates not observed with event and 1 indicates observed with event; One column of Event Type (even there is only one endpoint), values could be numeric or characters; One column of Time in days; Columns of Exposure Metrics in original scale (as many as needed); Columns of Covariates (as many as needed) if covariates search or demographic summary is requested; One column of Demographic-group-by variable, which could be one of the covariates or a new variable. The following is optional: - One column of Event Sub-Type, providing more detailed categories for Yes and No in each endpoint; - One column of Grade if the endpoints are related to Grades such as \\(\\le \\text{Grade} 2\\). Below is a subset of obsdata.csv in the example: PROT ID SEX RACE LOCATION AGE BWT TIME CAVE1 CAVE2 FLAG DV SUB C 2 1 1 3 2 55 64 57 0 0 1 0 3 NA 3 2 2 1 1 26 88 193 0 0 1 0 3 NA 2 3 2 2 1 50 55 191 0 0 1 0 3 NA 2 4 1 2 1 40 53 317 0 0 1 0 3 NA 1 5 2 4 1 39 76 199 0 0 1 0 3 NA 3 6 1 1 2 55 68 111 0 0 1 0 3 NA 2 1 1 3 2 55 64 57 0 0 2 1 2 NA 3 2 2 1 1 26 88 193 0 0 2 0 6 NA 2 3 2 2 1 50 55 191 0 0 2 0 5 NA 2 4 1 2 1 40 53 317 0 0 2 0 6 NA 1 5 2 4 1 39 76 199 0 0 2 0 5 NA 3 6 1 1 2 55 68 111 0 0 2 1 1 NA In this example, PROT is the Demographic-summary-by column. ID is the subject ID column, DV\" is the Outcome column. Time is the Time column in days. FLAG is the Event Type column. SUB is the Event Sub-Type, where the same value with different Event Type values means different event sub-type (nested within the Event Type). SEX, RACE, LOCATION, AGE, BWT are the covariates columns. The level values in categorical variables are coded in numbers, and the actual Labels can be provided by user in the control script. CAVE1 and CAVE2 are the Exposure Metric columns. 0 values will be replaced by 0.0001 while calculating the log-scale. 4.2 New Exposure Data Set for Prediction The new exposure data set need to contain A column of Group Label for summarizing the result; Columns of simulated New Exposure Metrics. The data set could contain any other columns. Below is a subset of the simulated new exposures simdata.csv in the example: GROUP CAVE1 CAVE2 C 100 mg QD 48.26489 60.89629 1 100 mg QD 172.61230 87.19719 1 100 mg QD 58.98776 85.84614 1 100 mg QD 56.19063 109.53101 1 100 mg QD 104.41777 83.96203 1 100 mg QD 283.81537 75.03528 1 50 mg QD 48.47262 124.34171 0 50 mg QD 32.14167 43.52486 0 50 mg QD 22.93323 33.95415 0 50 mg QD 87.91701 47.09609 0 50 mg QD 57.66175 41.51849 0 50 mg QD 42.05427 46.84531 0 30 mg QD 28.30073 16.79537 0 30 mg QD 28.31021 30.03572 0 30 mg QD 37.09448 35.19235 0 30 mg QD 34.85409 44.31023 0 30 mg QD 17.25611 20.07292 0 30 mg QD 20.40230 23.39462 0 In this example, each group has 2500 simulated exposures. In practice, the simulated exposures should be a value corresponding to 52 weeks/1 year of the treatment. For the columns in this example: GROUP is the Group Label column. It could be coded in numbers or characters. Levels and Labels can be specified by user in the control script. CAVE1 and CAVE2 are the simulated New Exposures Metrics. The exposure column names are not required to be the same as the modeling data set. User can provide the correspondence in the control script. C is the additional column for filtering the data set. All 100 mg QD rows are with C = 1. User may hide/only show the 100 mg QD group in the prediction result without modifying data set outside. "],["control-script-for-modeling-user-input.html", "Chapter 5 Control Script for Modeling: user-input.r 5.1 Data set 5.2 Unique Patient Identifier 5.3 Time 5.4 Endpoints to be analysed 5.5 Event Sub-Type Column and Set up (optional). 5.6 Grade column and Set up (optional). 5.7 Exposure Metrics 5.8 Categorical Covariates 5.9 Continuous Covariates 5.10 Reference Value for Continuous Covariates 5.11 Other Options", " Chapter 5 Control Script for Modeling: user-input.r There are many modeling options that are specified in the control scripts to see how modeling result may change. The options will all be presented in the context of the example dataset as that is considered to be the easiest way to present all the options in a clear manner. The example analysis has the following components which are specified in the user-input.r control file. 2 Exposure Metrics, 3 Categorical Covariates and 2 Continuous Covariates were considered in all 3 Endpoints; All exposures, covariates and events were summarized by protocol number (PROT). Threshold of low incidence rate was 10% therefore only 2 endpoints were considered in this analysis (Adverse Event 1 was with incidence rate lower than 10%). Event sub-type was provided for all endpoints, which breaks down the observed with event and not observed with event outcomes into more detailed classification. Included covariates in final model if there is any proper one(s). Considered log- and sqrt-transformation for exposure metrics. Considered log-transformation for continuous covariates. No reference value for continuous covariates. Exposure selection conducted following \\(p\\)-value significance criteria, and backwards deletion did not remove exposure metric regardless of significance. Final model may not contain exposure metric if none meet the exposure selection criteria. Tables are all saved as .tex (LaTex format). This section explains how to write a user-input.r control file for modeling. The examples showing below can be used as a template by combining all chunks in order(user needs to update the column names and options accordingly). The control script require package tidyverse. library(tidyverse) 5.1 Data set input.data.name is the data file for modeling. This data file must be under the directory of pathRunType. input.data.name &lt;- &quot;obsdata.csv&quot; 5.2 Unique Patient Identifier pat.num is the column name of the subject ID variable. pat.num &lt;- &quot;ID&quot; #ID is the column name in data set 5.3 Time EVDUR and EVDUR.unit are the time column name in the data set and the time unit. The time values must be in days. #Column for time in days EVDUR &lt;- &quot;TIME&quot; EVDUR.unit &lt;- &quot;days&quot; 5.4 Endpoints to be analysed This section introduces the complex set up regarding the endpoints. Outcome column and levels&amp;labels: dv &lt;- &quot;DV&quot; #DV is the outcome column name in data set # Levels as they appear in the dataset dv.levels &lt;- c(0, 1) # Labels you&#39;d like to see in the report dv.labels &lt;- c(&quot;No&quot;, &quot;Yes&quot;) Event Type (Endpoint flag) column # Column describing endpoints endpcolName &lt;- &quot;FLAG&quot; #FLAG is the flag column name in data set # Subset of endpoints in analysis dataset to be analyzed # Can be numbers or character strings, however they show up in the dataset endpoints &lt;- c(1,2,3) #the actual values in FLAG to be used in this analysis #endpoints &lt;- c(1,3) #FLAG=2 will be ignored in this analysis Event Names set up. Provide the name of each endpoint. # ENDPOINTS names. # Names for endpoints as they should appear in tables and figures. # Should be the same length as the &quot;endpoints&quot; vector above. # Any endpoint name cannot be a sub-string of the other one # Bad example #endpName &lt;- c(&quot;Adverse&quot;, # &quot;Adverse Event&quot;, # &quot;Adverse Event Type&quot;) # EXAMPLE: endpName &lt;- c(&quot;Adverse Event Type 1&quot;, &quot;Adverse Event Type 2&quot;, &quot;Adverse Event Type 3&quot;) endpName &lt;- sapply(X = endpName, simplify = F, USE.NAMES = T, FUN = function(n){ if(n == &quot;Adverse Event Type 1&quot;){ numb &lt;- endpoints[1] #FLAG = 1 (endpoints[1]) is &quot;Adverse Event Type 1&quot; label &lt;- n }else if(n == &quot;Adverse Event Type 2&quot;){ numb &lt;- endpoints[2] #FLAG = 2 (endpoints[2]) is &quot;Adverse Event Type 2&quot; label &lt;- n }else if(n == &quot;Adverse Event Type 3&quot;){ numb &lt;- endpoints[3] #FLAG = 3 (endpoints[3]) is &quot;Adverse Event Type 3&quot; label &lt;- n }else{ numb &lt;- 0 label &lt;- 0 } endp.list &lt;- c(numb, label) return(endp.list) } # function(n) ) # sapply 5.5 Event Sub-Type Column and Set up (optional). This section introduces the set up for event sub-type information. sub.endpcolName is the column name of the sub-type information, and sub.endpName connects the sub-type values to the endpoints names with proper sub-type names. In the example obsdata.csv, the values in column SUB were all in numbers, and they refer to different sub-type names for different endpoint types. sub.endpcolName and sub.endpName could be missing. sub.endpcolName &lt;- &quot;SUB&quot; #SUB is the column name in the data set sub.endpName &lt;- list(`Adverse Event Type 1` = c(`Severe` = 1, `Mild` = 2, `None` = 3), #Endpoint name = c(Actual sub-category name = Value in the column) `Adverse Event Type 2` = c(`SubType 1` = 1, `SubType 2` = 2, `SubType 3` = 3, `SubType 4` = 4, `SubType 5` = 5, `SubType 6` = 6), `Adverse Event Type 3` = c(`Severe` = 1, `Moderate` = 2, `Mild` = 3, `None` = 4)) 5.6 Grade column and Set up (optional). If the endpoints are grade related, provide the grade column name as dvg and a summary of grades within each endpoint will be generated. #The same column cannot be set as dvg and sub.endpcolName at the same time dvg &lt;- &quot;SUB&quot; #SUB is the column name in the data set dvg could be missing. Usually,dvg and sub.endpcolName are not both used in the same analysis. 5.7 Exposure Metrics This section is about the exposure metric information. Beside of the column names orig.exposureCov, user needs to provide the names of each exposure metric to show on table/figure or in the report context, as well as the endpoint(s) to use each exposure with. Provide Exposure Metric Columns # EXPOSURE covariates - list # Names should correspond to names in analysis dataset. # EXAMPLE: orig.exposureCov &lt;- c(&quot;CAVE1&quot;,&quot;CAVE2&quot;) #exposure metric column names in data Set up Exposure Metrics desc.exposureCov.1 &lt;- sapply(X = orig.exposureCov, simplify = F, USE.NAMES = T, FUN = function(f){ if(f == &quot;CAVE1&quot;){ #name to show in tables or figures title = &quot;C[ave1]~(ng/mL)&quot; #use ~ for white space; use [x] for subscript text label = &quot;Time-weighted average concentration A&quot; #Name to show in report context #end.p = c(endpoints[1]) #will be used in the first endpoint end.p = c(endpoints[1:3]) #will be used in all 3 endpoints }else if(f == &quot;CAVE2&quot;){ title = &quot;C[ave2]~(ng/mL)&quot; label = &quot;Time-weighted average concentration B&quot; end.p = c(endpoints[1:3]) }else{ } list(title = title, label = label, end.p = end.p) } # function(f) ) # sapply 5.8 Categorical Covariates The set up for categorical covariates is very similar to exposure metrics. Categorical covariates will have the same name on table/figure and in the report context. Categorical covariates can be provided as a summary-only variable, which will only show in the demographic summary and will be excluded in modeling covariates search. Categorical Covariates Column Names # CATEGORICAL covariates - list # Names should correspond to names in analysis dataset. # EXAMPLE: full.cat &lt;- c(&quot;RACE&quot;,&quot;SEX&quot;, &quot;LOCATION&quot;) Set Up Categorical Covariates # Assign more elaborate names and factor levels to categorical covs # NOTE: Assign the desired reference value as the first element of &quot;levels&quot; # EXAMPLE: full.cat.1 &lt;- sapply(X = full.cat, simplify = F, USE.NAMES = T, FUN = function(j){ if(j == &quot;RACE&quot;){ #categorical values are coded as numbers 1,2,3,4 in data set #the levels vector is corresponding to the order of numerical levels in the data set levels = c(&quot;White&quot;, &quot;Black&quot;, &quot;Asian&quot;, &quot;Other&quot;) #1=&quot;White&quot;, 2=&quot;Black&quot;, ... label = &quot;Race&quot; #Name of the variable to show in report #end.p = c(endpoints[1]) #use for the first endpoint #end.p = &quot;summary only&quot; #use for demographic summary only, won&#39;t be included in modeling end.p = c(endpoints[1:3]) #use for all endpoints }else if(j == &quot;SEX&quot;){ levels = c(&quot;Male&quot;, &quot;Female&quot;) label = &quot;Sex&quot; end.p = c(endpoints[1:3]) }else if(j == &quot;LOCATION&quot;){ levels = c(&quot;US&quot;, &quot;Non-US&quot;) label = &quot;Geographical~Location&quot; #use ~ for white space end.p = c(endpoints[1:3]) } list(levels = levels, label = label, end.p = end.p) } # function(j) ) # sapply 5.9 Continuous Covariates The set up for continuous covariates is very similar to exposure metrics. Continuous covariates will have the same name on table/figure and in the report context. Continuous covariates can be provided as a summary-only variable, which will only show in the demographic summary and will be excluded in modeling covariates search. Continuous Covariates Column Names # CONTINUOUS covariates - list # Names should correspond to names in analysis dataset. # EXAMPLE: orig.con &lt;- c(&quot;AGE&quot;,&quot;BWT&quot;) Set Up Continuous Covariates # Assign more elaborate names to continuous covs # Write what you want to end up in the plot(s) # EXAMPLE: orig.con.1 &lt;- sapply(X = orig.con, simplify = F, USE.NAMES = T, FUN = function(k){ if(k == &quot;AGE&quot;){ title = &quot;age&quot; #Name of the variable to show in report #end.p = c(endpoints[1]) #use for first endpoint #end.p = &quot;summary only&quot; #use for demographic summary only, won&#39;t be included in modeling end.p = c(endpoints[1:3]) }else if(k == &quot;BWT&quot;){ title = &quot;Baseline~Bodyweight~(kg)&quot; #use ~ for white space end.p = c(endpoints[1:3]) }else{ } list(title = title, end.p = end.p) } # function(k) ) # sapply 5.10 Reference Value for Continuous Covariates It is possible to use reference value for continuous covariates in the modeling. The default value of con.model.ref is No. Use Reference Value or Not #Use (continuous variable - reference) in model # con.model.ref &lt;- &quot;Yes&quot; #Not use (continuous variable - reference) in model con.model.ref &lt;- &quot;No&quot; #Default is &quot;No&quot; Provide Reference Value (Optional) #The reference number of each continuous variable #If not provided, will use median by default #con.ref&lt;- list(ref = c(AGE = 35, #variable name = reference value # BWT = 70), # #already.adjusted.in.data is always F, unless the values are already centered in the data set # already.adjusted.in.data = F) 5.11 Other Options Most of the options in this section have a numeric value or they are binary-indicator in TRUE/FALSE or Yes/No. 5.11.1 Demographic Summary-by Variable demog_grp_var can be any categorical variable in the data set. The default value is PROT. Error occurs if demog_grp_var is missing and PROT is not a column in the data set. # Grouping variable for demographic summaries demog_grp_var &lt;- &quot;PROT&quot; #Default is &quot;PROT&quot; # demog_grp_var &lt;- &quot;SEX&quot; 5.11.2 Additional Columns to Include In Modeling Dataset The saved modeling data set will only contains necessary columns (ID, Exposure Metrics, Event-related, Endpoint-related, Covariates, Additional Columns specified by use). ###Additional columns to carry with ###Could be missing add_col &lt;- c(&quot;DOSE&quot;) 5.11.3 Threshold(%) for Incidence Rate The endpoint will an incidence rate lower than the threshold will be ignored in the analysis. # threshold percentage for considering endpoints p.yes.low &lt;- 5 #Default value 10, must be between 0 and 100 5.11.4 Exposure Metric Selection Criteria Exposure Metric is selected for each endpoint following the same criteria chosen by the user. useDeltaD and p_val are key values. Select the exposure metric that satisfies the significant level # use p-value instead of Delta D useDeltaD &lt;- FALSE #Default value FALSE # significant level to an exposure metric to stay in base model p_val &lt;- 0.01 #Default significant level 0.01 If multiple exposure metrics meet the significant level, the one with the smallest \\(p\\)-value will be selected. If no exposure metric meets the significant level, the base model will not contain exposure metric. Or, select the exposure metric with largest change in Deviance \\(\\Delta D\\) regardless of significant level # use Delta D instead of p-value useDeltaD &lt;- TRUE #Default value FALSE If useDeltaD and p_val are missing in the control script, exposure metric will be selected as the one satisfies significant level 0.01 by default. 5.11.5 Covariates Search # Looking for covariates in modeling analyze_covs &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; if at least one covariate provided; otherwise &quot;No&quot; # threshold(%) for missing value proportion in continuous covariates # the variable will be ignored if the missing value is higher than the threshold p.icon &lt;- 10 #Default value 10, must be between 0 and 100 # threshold(%) for missing value proportion in categorical covariates # the variable will be ignored if the missing value is higher than the threshold p.icat &lt;- 10 #Default value 10, must be between 0 and 100 5.11.6 Backwards Deletion Criteria Final model is obtained via backwards deletion with the significant level specified by the use. #Significant level for a variable to stay in the final model p_val_b &lt;- 0.01 #Default significant level 0.01 #Exposure Metric will be in the final model regardless of the significant level. exclude.exp.met.bd &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; If p_val_b and exclude.exp.met.bd, backwards deletion will be conducted at significant level 0.01 by default and the selected exposure metric (if any) will not be removed by default. 5.11.7 Exposure Metrics and Continuous Covariates Scales If user chooses to consider scale transformation for exposure metrics or for continuous covariates, the transformed scales of variables (if any) will be compared with the original scales and only one scale of each variable could be included in the data set. For the exposure metrics, each scale of each metric will be assessed using a univariate model and the one that meets the exposure metric selection criteria will retain in the model. For the continuous covariates, the one with better normality will be selected from the original scale and the log-transformed scale. If the number of subjects is between 3 and 5000, Shapiro-Wilks normal test will be used; otherwise, Anderson-Darling will be used. # Taking log of exposure metrics log_exp &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; # Taking sqrt of exposure metrics sqrt_exp &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; # Taking log of continuous covariates log_covs &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; In log-transformation, values of zero will be replaced with 0.0001. 5.11.8 Odds-Ratio Results Odds-Ration result of categorical covariates will be generated and included in the report by default. To include continuous Covariates, user need to specify a vector of percentiles OR_con_perc where the odds-ratio of the change from median/reference value to each percentile will be shown in tables and figures. For example, the odds-ratio of Age will be shown as the odds-ratio of a decrease in Age from the median Age to 25th percentile in Age and an increase in Age from the median Age to 75th percentile in Age, instead of the odds-ratio of 1 unit increase in Age. #Odds Ratios plot for Continuous Variable #Compare from low-th percentile to up-th percentile #If any of them not specified, continuous variable will be removed from OR plots OR_con_perc &lt;- c(0.25,0.75) #values must be between 0 and 1 #Include Tables in the report OR_tab &lt;- &quot;No&quot; #Default value &quot;Yes&quot; #Include Figures in the report OR_fig &lt;- &quot;Yes&quot; #Default value &quot;Yes&quot; 5.11.9 Saved table format Tables can be saved in LaTex format (.tex) or in Tab-separated format (.tsv). The LaTex format is easy to be imported or inserted to a LaTex file, while the Tab-separated is easy to be copy&amp;paste in Excel then to be used in Word document. Either format can be used in the auto-generated report via ReportPoisson(). LaTex.table &lt;- TRUE #Default value FALSE "],["prediction-control-script-prediction-user-input-sim.html", "Chapter 6 Prediction Control Script prediction-user-input-sim.r 6.1 Bins of Observed Exposure Values 6.2 Simulated Exposure Data Set 6.3 New Exposure Summary Metric 6.4 Group Label Variable 6.5 Filter Condition (Optional) 6.6 Caption for Simulated Exposure Data", " Chapter 6 Prediction Control Script prediction-user-input-sim.r This section explains how to write a prediction-user-input-sim.r control file for predicting the incidence rate using new simulated exposures. The examples showing below can be used as a template by combining all chunks in order(user needs to update the column names and options accordingly). The control script require package tidyverse. library(tidyverse) 6.1 Bins of Observed Exposure Values The observed exposure values will be grouped into bins to calculate the observed incidence rates and they are compared to the model prediction. If bin_n_obs is missing, the observed exposures will be grouped into 5 bins by default. #number of bins for grouping exposure values of observations (the data used in modeling) bin_n_obs &lt;- 7 #Default value is 5 6.2 Simulated Exposure Data Set sim_inc_expo_data is the file name of the new exposure data set. It must under the same folder as all other modeling results. #Provide the new data set for prediction sim_inc_expo_data &lt;- &quot;simdata.csv&quot; Obs_Expo_list is the exposure metric (original scale) column names in obsdata.csv, and Sim_Expo_list is the corresponding names in simdata.csv. In many circumstances, the same exposure metric might have different column names in different data set. If Obs_Expo_list is missing, it will be set as all exposure metric column values occurred in obsdata.csv. If Sim_Expo_list is missing, it will be set as the same value as Obs_Expo_list #Selected Exposure Metric(s) column(s) in Obs Data (not sim data) shown on prediction plot #If Obs_Expo_list is missing, Obs_Expo_list = names(orig.exposureCov) which was saved in the modeling result Obs_Expo_list &lt;- c(&quot;CAVE1&quot;, &quot;CAVE2&quot;) #Metric column(s) in simulation data to be used as Exposure(s) on plot #the order needs to be consistent with Obs_Expo_list #If Sim_Expo_list is missing, Sim_Expo_list = Obs_Expo_list Sim_Expo_list &lt;- c(&quot;CAVE1&quot;, &quot;CAVE2&quot;) 6.3 New Exposure Summary Metric The center of exposures in each group can be calculated as the geometric mean: #Statistic of Exposure used to calculate fitted value. #&quot;median&quot;, &quot;geomean&quot;; Center_Metric &lt;- &quot;geomean&quot; #Default value &quot;geomean&quot; Center_Metric_name &lt;- &quot;geometric mean&quot; It could also be calculated as the median: #Statistic of Exposure used to calculate fitted value. #&quot;median&quot;, &quot;geomean&quot;; Center_Metric &lt;- &quot;median&quot; #Default value &quot;geomean&quot; Center_Metric_name &lt;- &quot;Median&quot; If Center_Metric is missing, the default value is geomean. If Center_Metric_name is missing, the metric name will be geometric mean or median based on Center_Metric. 6.4 Group Label Variable grp_colname is the variable to summary and display exposure values by. grp_colname_tab is the name to display in tables. If grp_colname is missing, the exposure values will be summarized and displayed as one group; if grp_colname_tab is missing, the default value is Label. #Group Label column name grp_colname &lt;- &quot;GROUP&quot; #column name in simdata.csv grp_colname_tab &lt;- &quot;Treatment&quot; #name to display in tables levels.grp and labels.grp are the levels information for the group variable. #provide levels in Group Label column #if levels.grp is missing, a vector of the unique values in grp_colname will be levels.grp levels.grp &lt;- c(&quot;10 mg QD&quot;, &quot;30 mg QD&quot;, &quot;50 mg QD&quot;, &quot;100 mg QD&quot;) #provide labels of each level in Group Label column #if labels.grp is missing, labels.grp = levels.grp labels.grp &lt;- c(&quot;10 mg once daily&quot;, &quot;30 mg once daily&quot;, &quot;50 mg once daily&quot;, &quot;100 mg once daily&quot;) 6.5 Filter Condition (Optional) It is possible to use a subset of simdata.csv without modifying the data file. # Only include partial exposure records filter_condition &lt;- &quot;GROUP != &#39;10 mg QD&#39;&quot; #remove 10 mg QD group #In the example simdata.csv, only 100 mg QD has C = 1 #filter_condition &lt;- &quot;C == 1&quot; # only keep 100 mg QD group #filter_condition &lt;- &quot;GROUP == &#39;100 mg QD&#39;&quot; filter_condition can be missing if all exposure values will be used. 6.6 Caption for Simulated Exposure Data Add information for the simulated exposure data. If expo_pred_tab_caption is missing, the standard description will be used: Predicted exposure metric for each dose are derived from simulated patients with randomly drawn random effect parameters as described by the final population PK model and body weights sampled from observations. expo_pred_tab_caption &lt;- &quot;Predicted exposure metric values for each dose are derived from 2,500 simulated subjects.&quot; "],["example-adjusting-output.html", "Chapter 7 Example Adjusting Output 7.1 Demographic Summary Tables 7.2 Use different Exposure Metrics in different Endpoints 7.3 Threshold(%) for Incidence Rate 7.4 Exposure and Model Selection Criteria 7.5 Scale of Exposure Metrics 7.6 Covariates Search 7.7 Summary-only Covariates 7.8 Reference value for Continuous Covariates 7.9 Save all tables as .tsv files instead of .tex files", " Chapter 7 Example Adjusting Output This section provides ideas to adjust the output of the provided examples by editing control script. 7.1 Demographic Summary Tables The default for summarizing is to summarize by study. However, it is possible to summarize all the exposure metrics and other covariates by levels of a categorical covariate. The following adjustment to the control script will result in a summary table summarized across Sex (ie Male and Female). demog_grp_var &lt;- &quot;SEX&quot; 7.2 Use different Exposure Metrics in different Endpoints There may be situations where each of the exposure metrics are not of interest for all of the endpoints. This may also be the case if a full analysis is desired for each of the exposure metrics. For the example analysis, the following change will result in using CAVE1 for only for endpoint 1 and use CAVE2 only for endpoints 2 and 3. orig.exposureCov &lt;- c(&quot;CAVE1&quot;,&quot;CAVE2&quot;) #exposure metric column names in data desc.exposureCov.1 &lt;- sapply(X = orig.exposureCov, simplify = F, USE.NAMES = T, FUN = function(f){ if(f == &quot;CAVE1&quot;){ #name to show in tables or figures title = &quot;C[ave1]~(ng/mL)&quot; #use ~ for white space; use [x] for subscript text label = &quot;Time-weighted average concentration A&quot; #Name to show in report context end.p = c(endpoints[1]) #will be used in the first endpoint #end.p = c(endpoints[1:3]) #will be used in all 3 endpoints }else if(f == &quot;CAVE2&quot;){ title = &quot;C[ave2]~(ng/mL)&quot; label = &quot;Time-weighted average concentration B&quot; end.p = c(endpoints[2:3]) #end.p = c(endpoints[1:3]) }else{ } list(title = title, label = label, end.p = end.p) } # function(f) ) # sapply 7.3 Threshold(%) for Incidence Rate In the event that an event incidence rate is low, the analyst should seriously consider if this analysis is appropriate. The statistical properties for generalized linear models may not hold when there is a low incidence rate. It is not recommended to reduce the incidence rate threshold below 10%. In the example analysis, setting the incidence rate to be at least 5%, setting p.yes.low to 5, then Adverse Event Type 1 will be included in the analysis regardless of its low incidence rate. # threshold percentage for considering endpoints p.yes.low &lt;- 5 #Default value 10, must be between 0 and 100 7.4 Exposure and Model Selection Criteria The default criteria for covariate evaluation is to use a p-value significance. When there is no exposure response relationship, or it is a weak relationship, a small p_val may result in no exposure metric selected during the exposure selection stage of the analysis. It is possible to use \\(\\Delta D\\) as the exposure selection criteria which compares nested models for model overall model improvement. The best exposure metric will be selected regardless of its significance. # use Delta D instead of p-value # useDeltaD &lt;- FALSE useDeltaD &lt;- TRUE #Default value FALSE #significant level to an exposure metric to stay in base model #p_val &lt;- 0.01 #Default significant level 0.01 Change the criteria for covariates to stay in final model during the backwards deletion. #Significant level for a variable to stay in the final model #p_val_b &lt;- 0.01 #Default significant level 0.01 p_val_b &lt;- 0.1 Let the selected exposure metric be removed if it does not meet the backwards deletion criteria. #Exposure Metric will be in the final model regardless of the significant level. exclude.exp.met.bd &lt;- &quot;No&quot; #Default value &quot;Yes&quot; 7.5 Scale of Exposure Metrics In order to evaluate exposure metrics on the original scale and not consider any transformations, the following arguments should be changed to: log_exp &lt;- &quot;No&quot; #Default value &quot;Yes&quot; sqrt_exp &lt;- &quot;No&quot; #Default value &quot;Yes&quot; 7.6 Covariates Search In some instances, relationship between the endpoint and covariates may not be of interest. The covariate evaluation will not be performed and the final model will only include the best exposure metric, provided it meet the significance criteria for inclusion. #Looking for covariates in modeling analyze_covs &lt;- &quot;No&quot; #Default value &quot;Yes&quot; if at least one covariate provided; otherwise &quot;No&quot; 7.7 Summary-only Covariates There may be occasions when additional summary information in desired, but the variable is not desired for the analysis. Categorical and/or continuous covariates can be declares as summary only meaning they will only be included in the summary tables. In the code chunk below, the covariate body wright (BWT) will only be included as a summary-only variable. ... title = &quot;Baseline~Bodyweight~(kg)&quot; #use ~ for white space end.p = &quot;summary only&quot; #end.p = c(endpoints[1:3]) ... Covariate(s) will still show in demographic summary tables but wont be included in modeling. Modeling results might change. Exposure Metrics must be used for at least one endpoint in modeling. 7.8 Reference value for Continuous Covariates To use reference value for continuous covariates con.model.ref &lt;- &quot;Yes&quot; # default is &quot;No&quot; To provide reference values instead of using median values con.model.ref &lt;- &quot;Yes&quot; con.ref&lt;- list(ref = c(AGE = 35, #variable name = reference value BWT = 70), already.adjusted.in.data = F) 7.9 Save all tables as .tsv files instead of .tex files LaTex.table &lt;- FALSE "],["acknowledgements.html", "Chapter 8 Acknowledgements", " Chapter 8 Acknowledgements Many thanks to Jessica Wojciechowski, Ph.D. Donald Irby, Ph.D. Yeamin Huh, Ph.D. Vivek S Purohit, Ph.D. Timothy Nicholas, Ph.D. "]]
